{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import src.graph_ops as go\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = np.load(\"graphs_updated.npy\")\n",
    "# options: graph_10+20k, graph_10+10k\n",
    "labels = np.load(\"labels.npy\")\n",
    "# options: labels_10+20k, labels_10+10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = go.compress_graphs(graphs)\n",
    "X = X[:,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.get_dummies(labels[:,0])\n",
    "first[18] = 0\n",
    "first[19] = 0\n",
    "y = (first + pd.get_dummies(labels[:,1])).values\n",
    "first = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(input, target, size_average=True):\n",
    "    \"\"\" Cross entropy that accepts soft targets\n",
    "    Args:\n",
    "         pred: predictions for neural network\n",
    "         targets: targets, can be soft\n",
    "         size_average: if false, sum is returned instead of mean\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        input = torch.FloatTensor([[1.1, 2.8, 1.3], [1.1, 2.1, 4.8]])\n",
    "        input = torch.autograd.Variable(out, requires_grad=True)\n",
    "\n",
    "        target = torch.FloatTensor([[0.05, 0.9, 0.05], [0.05, 0.05, 0.9]])\n",
    "        target = torch.autograd.Variable(y1)\n",
    "        loss = cross_entropy(input, target)\n",
    "        loss.backward()\n",
    "    \"\"\"\n",
    "    return torch.mean(-target * torch.log(input))\n",
    "\n",
    "\n",
    "class LSTM(nn.Module): \n",
    "    \n",
    "    #constructor\n",
    "    #take in X as a parameter\n",
    "    def __init__(self, X, y, hidden_dim = 50, num_layers = 4, weight_decay = 0.0005):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.device = 'cpu'\n",
    "        \n",
    "        #Find dimensionality of X, y\n",
    "        X_dim = X.shape[-1]\n",
    "        y_dim = y.shape[-1]\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(X_dim, hidden_dim, num_layers)\n",
    "        \n",
    "        #Output\n",
    "        self.linear = nn.Linear(hidden_dim, y_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "        # Define what optimization we want to use.\n",
    "        # Adam is a popular method so I'll use it.\n",
    "        # L2 regularization in weight decay.\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay = weight_decay)\n",
    "        self.to(self.device)\n",
    "        \n",
    "    # 1. input X\n",
    "    def forward(self, X):\n",
    "        X, _ = self.lstm(X)\n",
    "        X = self.linear(X)\n",
    "        X = self.sigmoid(X)\n",
    "        X = 2*X/((X[:,0,:]).sum(1))[:,None,None]\n",
    "        return X\n",
    "    \n",
    "    def loss(self, pred, true):\n",
    "        #PyTorch's own cross entropy loss function.\n",
    "        score = cross_entropy\n",
    "        l = None\n",
    "        for i in range(true.shape[1]):\n",
    "            if l is None:\n",
    "                l = score(pred[:,0,i], true[:,i])\n",
    "            else:\n",
    "                l += score(pred[:,0,i], true[:,i])\n",
    "        return l\n",
    "    \n",
    "\n",
    "    def fit(self, X, y, early_stopping = True, patience = 50):\n",
    "        \n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_arr = X.values\n",
    "            X_tens = Variable(torch.Tensor(X_arr).float())\n",
    "        else:\n",
    "            X_tens = Variable(torch.Tensor(X).float())\n",
    "        if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "            y_arr = y.values\n",
    "            if len(y_arr.shape) == 1:\n",
    "                y_arr = y_arr[:,None]\n",
    "            y_tens = Variable(torch.Tensor(y_arr).float())\n",
    "        else:\n",
    "            if len(y.shape) == 1:\n",
    "                y = y[:,None]\n",
    "            y_tens = Variable(torch.Tensor(y).float())\n",
    "        \n",
    "        X_tens = X_tens.to(self.device)\n",
    "        y_tens = y_tens.to(self.device)\n",
    "        \n",
    "        if early_stopping == True:\n",
    "            \n",
    "            inds = np.arange(len(X_tens))\n",
    "            num_train = int(len(X_tens) * .9)\n",
    "            train_inds = np.random.choice(inds, num_train, replace=False)\n",
    "            val_inds = np.setdiff1d(inds, train_inds)\n",
    "            X_train = X_tens[train_inds]\n",
    "            y_train = y_tens[train_inds]\n",
    "            X_val = X_tens[val_inds]\n",
    "            y_val = y_tens[val_inds]\n",
    "            \n",
    "        for epoch in range(1000):\n",
    "            self.optimizer.zero_grad()\n",
    "            if early_stopping==True:\n",
    "                out_train = self.forward(X_train)\n",
    "                loss = self.loss(out_train, y_train)\n",
    "            if early_stopping==False:\n",
    "                out_train = self.forward(X_tens)\n",
    "                loss = self.loss(out_train, y_tens)\n",
    "                print(loss)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                continue\n",
    "                \n",
    "            out_val = self.forward(X_val)\n",
    "            loss_val = self.loss(out_val, y_val)\n",
    "            print(loss_val)\n",
    "\n",
    "\n",
    "            if epoch == 0:\n",
    "                min_loss = loss_val\n",
    "                best_weights = self.state_dict()\n",
    "                counter = 0\n",
    "            else:\n",
    "                if loss_val < min_loss:\n",
    "                    min_loss = loss_val\n",
    "                    best_weights = self.state_dict()\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    if counter == patience:\n",
    "                        self.load_state_dict(best_weights)\n",
    "                        return\n",
    "                \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_arr = X.values\n",
    "            X_tens = Variable(torch.Tensor(X_arr).float())\n",
    "        else:\n",
    "            X_tens = Variable(torch.Tensor(X).float())\n",
    "            \n",
    "        X_tens = X_tens.to(self.device)\n",
    "        \n",
    "        predict_out = self.forward(X_tens)\n",
    "        temp =  predict_out.cpu().detach().numpy()\n",
    "        temp[temp > 1-1e-6] = 1-1e-6\n",
    "        temp[temp < 1e-6]=1e-6\n",
    "        temp = temp[:,0,:]\n",
    "        return temp\n",
    "    \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X).argsort(1)[:,-2:]\n",
    "        proba.sort(1)\n",
    "        return proba\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_true = y.argsort(1)[:,-2:]\n",
    "        y_true.sort(1)\n",
    "        return (y_pred == y_true).all(1).mean().item()\n",
    "    \n",
    "    def top_k_acc(self, X,y, k = 5):\n",
    "        \"\"\"Get top k accuracy for prediction. I.e., were the 2 correct nodes \n",
    "        in the top k returned. Note, k=2 is the score function.\"\"\"\n",
    "        y_pred = self.predict_proba(X)\n",
    "        y_true = y.argsort(1)[:,-2:]  \n",
    "        y_true.sort(1)\n",
    "        eqs_list = []\n",
    "        top_k = y_pred.argsort(1)[:,-k:]\n",
    "        for i in range(y_true.shape[0]):\n",
    "            row = y_true[i]\n",
    "            eqs_arr = []\n",
    "            for ele in row:\n",
    "                eqs_arr.append(np.any(ele == top_k[i]))\n",
    "            eqs_arr = np.array(eqs_arr)\n",
    "            eq = eqs_arr.all()\n",
    "            eqs_list.append(eq)\n",
    "        eqs = np.array(eqs_list)\n",
    "\n",
    "        return eqs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5969, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5971, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lstm.fit(X_train, y_train, early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3356"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6656"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.top_k_acc(X_test, y_test, k = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Tutorial]",
   "language": "python",
   "name": "conda-env-Tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
