{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_3layers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jKvjcrKTA_-F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yc5liH3A_-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "graphs = np.load(\"graphs_20node39500.npy\")\n",
        "# options: graphs_10+20k, graphs_10+10k\n",
        "labels = np.load(\"labels_20node39500.npy\")\n",
        "# options: labels_10+20k, labels_10+10k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_4jK9z90A_-K",
        "colab_type": "code",
        "outputId": "e5de3cb4-cf6f-4e1d-f4f3-37029d1506a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "num_of_graphs = graphs.shape[0]\n",
        "num_of_nodes = graphs.shape[1]\n",
        "\n",
        "\n",
        "def compress_graphs(graphs):\n",
        "    \"\"\"Convert 3d matrix of graphs, dims = (graphs,verts,verts), \n",
        "    to 2d matrix dims = (n_graphs, (verts choose 2) - verts). \n",
        "    We can omit half of the data as the matrix of each graph is \n",
        "    symmetric as we are working with undirected graphs. We can\n",
        "    also not take any entries on the main diagonal as they will \n",
        "    always be zero as we do not allow self loops.\n",
        "    \n",
        "    \n",
        "    Args: \n",
        "        graphs : (n_graphs,verts,verts) hypermatrix of graphs.\n",
        "        \n",
        "    Returns:\n",
        "        graphs_comp : (n_graphs, (vert choose 2) - verts) matrix\n",
        "            of compressed adjancey matrices.\n",
        "        \n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    verts = graphs.shape[1]\n",
        "    graphs_comp =  graphs.T[np.triu_indices(verts, 1)].T\n",
        "    \n",
        "    return graphs_comp  \n",
        "\n",
        "# compress 2d adjacency matrix to 1d array, prepare input\n",
        "compressed_graph = np.zeros((graphs.shape[0], int(num_of_nodes*(num_of_nodes-1)/2)))\n",
        "                            \n",
        "for i in range(0,graphs.shape[0]):\n",
        "    compressed_graph[i] = compress_graphs(graphs[i])\n",
        "\n",
        "graphs_train, graphs_test, train_labels, val_labels =\\\n",
        "    train_test_split(compressed_graph, labels, test_size=0.20, random_state=42)\n",
        "\n",
        "batch_size = 64\n",
        "params = {'batch_size': batch_size,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 6}\n",
        "max_epochs = 200\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, list_IDs, labels):\n",
        "        'Initialization'\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return num_of_graphs\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID = index\n",
        "\n",
        "        # Load data and get label\n",
        "        X = Variable(torch.from_numpy(compressed_graph[ID]))\n",
        "        y = self.labels[ID]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "# Generators\n",
        "training_set = Dataset(graphs_train, labels)\n",
        "training_generator = data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = Dataset(graphs_test, labels)\n",
        "validation_generator = data.DataLoader(validation_set, **params)\n",
        "\n",
        "class CompressMatrixNetwork(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        u = int(num_of_nodes*(num_of_nodes-1)/2)\n",
        "        self.fc1 = nn.Linear(u, 2*u)\n",
        "        self.fc3 = nn.Linear(2*u, 85)\n",
        "        self.fc4 = nn.Linear(85, 40)\n",
        "        self.fc5 = nn.Linear(85, 40)\n",
        "        self.fc6 = nn.Linear(40, num_of_nodes)\n",
        "        self.fc7 = nn.Linear(40, num_of_nodes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x1 = F.relu(self.fc4(x))\n",
        "        x1 = self.fc6(x1)\n",
        "        x2 = F.relu(self.fc5(x))\n",
        "        x2 = self.fc7(x2)\n",
        "        return F.softmax(x1, dim=1), F.softmax(x2, dim=1)\n",
        "\n",
        "model = CompressMatrixNetwork()\n",
        "\n",
        "for module in model.children():\n",
        "    module.reset_parameters()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "\n",
        "info = []\n",
        "# Loop over epochs\n",
        "for epoch in range(max_epochs):\n",
        "    epoch_train_acc, correct_count = 0, 0\n",
        "    epoch_val_acc = 0\n",
        "    epoch_train_loss = 0\n",
        "    epoch_val_loss=0\n",
        "    count = 0\n",
        "    \n",
        "    # Training\n",
        "    for local_batch, local_labels in training_generator:\n",
        "        # Transfer to GPU\n",
        "        if torch.cuda.is_available():\n",
        "            local_batch, local_labels = local_batch.cuda(), local_labels.cuda()\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        label_batch = local_labels.long()\n",
        "        input_batch = local_batch.float()\n",
        "\n",
        "        output_batch = model(input_batch)\n",
        "\n",
        "        train_loss = F.cross_entropy(output_batch[0], label_batch[:,0]) \\\n",
        "            + F.cross_entropy(output_batch[1], label_batch[:,1])\n",
        "        epoch_train_loss += train_loss\n",
        "\n",
        "        \n",
        "        pred1 = output_batch[0].data.max(1)[1]\n",
        "        pred2 = output_batch[1].data.max(1)[1]\n",
        "        \n",
        "        matches = (label_batch[:,0] == pred1) & (label_batch[:,1] == pred2)\n",
        "        epoch_train_acc += matches.float().mean()\n",
        "        correct_count += matches.sum()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        count += 1\n",
        "    epoch_train_loss = epoch_train_loss / count\n",
        "    epoch_train_acc = epoch_train_acc / count\n",
        "    # Validation\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for local_batch, local_labels in validation_generator:\n",
        "            # Transfer to GPU\n",
        "            local_batch, local_labels = local_batch.cuda(), local_labels.cuda()\n",
        "\n",
        "            model.eval()\n",
        "            \n",
        "            label_batch = local_labels.long()\n",
        "            input_batch = local_batch.float()\n",
        "            \n",
        "            output_batch = model(input_batch)\n",
        "            \n",
        "            \n",
        "            val_loss = F.cross_entropy(output_batch[0], label_batch[:,0]) \\\n",
        "                + F.cross_entropy(output_batch[1], label_batch[:,1])\n",
        "            epoch_val_loss += val_loss\n",
        "\n",
        "            pred1 = output_batch[0].data.max(1)[1]\n",
        "            pred2 = output_batch[1].data.max(1)[1]\n",
        "            \n",
        "            matches = (label_batch[:,0] == pred1) & (label_batch[:,1] == pred2)\n",
        "            epoch_val_acc += matches.float().mean()\n",
        "            count += 1\n",
        "        epoch_val_loss = epoch_val_loss / count\n",
        "        epoch_val_acc = epoch_val_acc / count\n",
        "    info.append([epoch, epoch_train_loss, epoch_val_loss, epoch_train_acc, epoch_val_acc])\n",
        "    print('epoch {:5d}: Obtained a training acc of {:.3f}.'.format(epoch, epoch_train_acc))\n",
        "    print('epoch {:5d}: Obtained a validation acc of {:.3f}.'.format(epoch, epoch_val_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch     0: Obtained a training acc of 0.104.\n",
            "epoch     0: Obtained a validation acc of 0.208.\n",
            "epoch     1: Obtained a training acc of 0.248.\n",
            "epoch     1: Obtained a validation acc of 0.316.\n",
            "epoch     2: Obtained a training acc of 0.323.\n",
            "epoch     2: Obtained a validation acc of 0.329.\n",
            "epoch     3: Obtained a training acc of 0.328.\n",
            "epoch     3: Obtained a validation acc of 0.329.\n",
            "epoch     4: Obtained a training acc of 0.330.\n",
            "epoch     4: Obtained a validation acc of 0.336.\n",
            "epoch     5: Obtained a training acc of 0.333.\n",
            "epoch     5: Obtained a validation acc of 0.335.\n",
            "epoch     6: Obtained a training acc of 0.333.\n",
            "epoch     6: Obtained a validation acc of 0.336.\n",
            "epoch     7: Obtained a training acc of 0.334.\n",
            "epoch     7: Obtained a validation acc of 0.333.\n",
            "epoch     8: Obtained a training acc of 0.335.\n",
            "epoch     8: Obtained a validation acc of 0.330.\n",
            "epoch     9: Obtained a training acc of 0.335.\n",
            "epoch     9: Obtained a validation acc of 0.337.\n",
            "epoch    10: Obtained a training acc of 0.336.\n",
            "epoch    10: Obtained a validation acc of 0.338.\n",
            "epoch    11: Obtained a training acc of 0.336.\n",
            "epoch    11: Obtained a validation acc of 0.338.\n",
            "epoch    12: Obtained a training acc of 0.337.\n",
            "epoch    12: Obtained a validation acc of 0.338.\n",
            "epoch    13: Obtained a training acc of 0.338.\n",
            "epoch    13: Obtained a validation acc of 0.337.\n",
            "epoch    14: Obtained a training acc of 0.338.\n",
            "epoch    14: Obtained a validation acc of 0.340.\n",
            "epoch    15: Obtained a training acc of 0.338.\n",
            "epoch    15: Obtained a validation acc of 0.339.\n",
            "epoch    16: Obtained a training acc of 0.337.\n",
            "epoch    16: Obtained a validation acc of 0.339.\n",
            "epoch    17: Obtained a training acc of 0.338.\n",
            "epoch    17: Obtained a validation acc of 0.341.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2bDmOMYUA_-M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x, y11, y12, y21, y22 = zip(*info)\n",
        "fig, ax = plt.subplots(2, 1, sharex=True)\n",
        "ax[0].plot(x, y11, x, y12)\n",
        "ax[0].legend(['Train loss', 'Val loss'])\n",
        "ax[1].plot(x, y21, x, y22)\n",
        "ax[1].legend(['Train acc', 'Val acc'])\n",
        "ax[1].set_ylim([0.0, 1.0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}