{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_graphs = 10000\n",
    "num_of_nodes = 20\n",
    "#graphs = generate_graphs(num_of_nodes, num_of_graphs)\n",
    "graphs = np.load(\"graphs_updated.npy\")\n",
    "labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_graphs(graphs):\n",
    "    \"\"\"Convert 3d matrix of graphs, dims = (graphs,verts,verts), \n",
    "    to 2d matrix dims = (n_graphs, (verts choose 2) - verts). \n",
    "    We can omit half of the data as the matrix of each graph is \n",
    "    symmetric as we are working with undirected graphs. We can\n",
    "    also not take any entries on the main diagonal as they will \n",
    "    always be zero as we do not allow self loops.\n",
    "    \n",
    "    \n",
    "    Args: \n",
    "        graphs : (n_graphs,verts,verts) hypermatrix of graphs.\n",
    "        \n",
    "    Returns:\n",
    "        graphs_comp : (n_graphs, (vert choose 2) - verts) matrix\n",
    "            of compressed adjancey matrices.\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    verts = graphs.shape[1]\n",
    "    graphs_comp =  graphs.T[np.triu_indices(verts, 1)].T\n",
    "    \n",
    "    return graphs_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress 2d adjacency matrix to 1d array, prepare input\n",
    "compressed_graph = np.zeros((graphs.shape[0], num_of_nodes*(num_of_nodes-1)/2))\n",
    "for i in range(0,graphs.shape[0]):\n",
    "    compressed_graph[i] = compress_graphs(graphs[i])\n",
    "\n",
    "graphs_train, graphs_test, train_labels, val_labels =\\\n",
    "\ttrain_test_split(compressed_graph, labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(batch_size, training=True):\n",
    "    \"\"\"Create a batch of examples.\n",
    "  \n",
    "    This creates a batch of input graphs and a batch of corresponding\n",
    "    ground-truth labels. We assume CUDA is available (with a GPU).\n",
    "  \n",
    "    Args:\n",
    "        batch_size: An integer.\n",
    "        training: A boolean. If True, grab examples from the training\n",
    "        set; otherwise, grab them from the validation set.\n",
    "    Returns:\n",
    "        A tuple,\n",
    "        input_batch: A Variable of floats with shape\n",
    "        [batch_size, 1, height, width]\n",
    "        label_batch: A Variable of ints with shape\n",
    "        [batch_size].\n",
    "    \"\"\"\n",
    "    if training:\n",
    "        random_ind = np.random.choice(graphs_train.shape[0], size=batch_size, replace=False)\n",
    "        input_batch = graphs_train[random_ind]\n",
    "        label_batch = train_labels[random_ind]\n",
    "    else:\n",
    "        input_batch = graphs_test[:batch_size]\n",
    "        label_batch = val_labels[:batch_size]\n",
    " \n",
    "  \n",
    "    volatile = not training\n",
    "    if volatile:\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                input_batch = Variable(torch.from_numpy(input_batch).cuda())\n",
    "                label_batch = Variable(torch.from_numpy(label_batch).cuda())\n",
    "            else:\n",
    "                input_batch = Variable(torch.from_numpy(input_batch))\n",
    "                label_batch = Variable(torch.from_numpy(label_batch))\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            input_batch = Variable(torch.from_numpy(input_batch).cuda())\n",
    "            label_batch = Variable(torch.from_numpy(label_batch).cuda())\n",
    "        else:\n",
    "            input_batch = Variable(torch.from_numpy(input_batch))\n",
    "            label_batch = Variable(torch.from_numpy(label_batch))\n",
    "        \n",
    "\n",
    "    return input_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_size=50):\n",
    " \n",
    "    model.train()\n",
    "    correct_count, total_loss, total_acc = 0., 0., 0.\n",
    "    \n",
    "    input_batch, label_batch = batch(batch_size, training=True)\n",
    "\n",
    "    label_batch = label_batch.long()\n",
    "    input_batch = input_batch.float()\n",
    "\n",
    "    output_batch = model(input_batch)\n",
    "\n",
    "    loss = F.cross_entropy(output_batch[0], label_batch[:,0]) \\\n",
    "        + F.cross_entropy(output_batch[1], label_batch[:,1])\n",
    "    \n",
    "    pred1 = output_batch[0].data.max(1)[1]\n",
    "    pred2 = output_batch[1].data.max(1)[1]\n",
    "    matches = (label_batch[:,0] == pred1) & (label_batch[:,1] == pred2)\n",
    "    accuracy = matches.float().mean()\n",
    "    correct_count += matches.sum()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    return loss.data.item(), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val():\n",
    "    \n",
    "    model.eval()\n",
    "    input_batch, label_batch = batch(graphs_test.shape[0], training=False)\n",
    "    \n",
    "    label_batch = label_batch.long()\n",
    "    input_batch = input_batch.float()\n",
    "    \n",
    "    output_batch = model(input_batch)\n",
    "    \n",
    "    \n",
    "    loss = F.cross_entropy(output_batch[0], label_batch[:,0]) \\\n",
    "        + F.cross_entropy(output_batch[1], label_batch[:,1])\n",
    "    \n",
    "    pred1 = output_batch[0].data.max(1)[1]\n",
    "    pred2 = output_batch[1].data.max(1)[1]\n",
    "    \n",
    "    matches = (label_batch[:,0] == pred1) & (label_batch[:,1] == pred2)\n",
    "    accuracy = matches.float().mean()\n",
    "    \n",
    "    return loss.data.item(), accuracy   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressMatrixNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_of_nodes*(num_of_nodes-1)/2), 570)\n",
    "        self.fc2 = nn.Linear(570, 380)\n",
    "        self.fc3 = nn.Linear(380, 85)\n",
    "        self.fc4 = nn.Linear(85, 40)\n",
    "        self.fc5 = nn.Linear(85, 40)\n",
    "        self.fc6 = nn.Linear(40, num_of_nodes)\n",
    "        self.fc7 = nn.Linear(40, num_of_nodes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x1 = F.relu(self.fc4(x))\n",
    "        x1 = self.fc6(x1)\n",
    "        x2 = F.relu(self.fc5(x))\n",
    "        x2 = self.fc7(x2)\n",
    "        return F.softmax(x1, dim=1), F.softmax(x2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0: Obtained a best validation acc of 0.001.\n",
      "Step    27: Obtained a best training acc of 0.040.\n",
      "Step    39: Obtained a best training acc of 0.080.\n",
      "Step    40: Obtained a best training acc of 0.120.\n",
      "Step    42: Obtained a best training acc of 0.200.\n",
      "Step    44: Obtained a best training acc of 0.280.\n",
      "Step    46: Obtained a best training acc of 0.360.\n",
      "Step    49: Obtained a best training acc of 0.420.\n",
      "Step    50: Obtained a best validation acc of 0.354.\n",
      "Step    63: Obtained a best training acc of 0.460.\n",
      "Step    69: Obtained a best training acc of 0.480.\n",
      "Step   100: Obtained a best validation acc of 0.358.\n",
      "Step   219: Obtained a best training acc of 0.500.\n",
      "Step   426: Obtained a best training acc of 0.520.\n",
      "Step   496: Obtained a best training acc of 0.580.\n",
      "Step  3040: Obtained a best training acc of 0.600.\n",
      "Step  4737: Obtained a best training acc of 0.640.\n"
     ]
    }
   ],
   "source": [
    "model = CompressMatrixNetwork()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for module in model.children():\n",
    "    module.reset_parameters()\n",
    "\n",
    "info = []\n",
    "fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "num_steps = 10000\n",
    "num_steps_per_val = 50\n",
    "best_val_acc = 0.0\n",
    "best_train_acc = 0.0\n",
    "for step in range(num_steps):\n",
    "    train_loss, train_acc = train_step()\n",
    "    if step % num_steps_per_val == 0:\n",
    "        val_loss, val_acc = val()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        print('Step {:5d}: Obtained a best validation acc of {:.3f}.'.format(step, best_val_acc))\n",
    "    if train_acc > best_train_acc:\n",
    "        best_train_acc = train_acc\n",
    "        print('Step {:5d}: Obtained a best training acc of {:.3f}.'.format(step, best_train_acc))\n",
    "    info.append([step, train_acc, val_loss, train_acc, val_acc])\n",
    "    x, y11, y12, y21, y22 = zip(*info)\n",
    "    ax[0].plot(x, y11, x, y12)\n",
    "    ax[0].legend(['Train loss', 'Val loss'])\n",
    "    ax[1].plot(x, y21, x, y22)\n",
    "    ax[1].legend(['Train acc', 'Val acc'])\n",
    "    ax[1].set_ylim([0.0, 0.25])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
