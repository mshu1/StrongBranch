{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import src.graph_ops as go\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = np.load(\"graphs_updated.npy\")\n",
    "# options: graph_10+20k, graph_10+10k\n",
    "labels = np.load(\"labels.npy\")\n",
    "# options: labels_10+20k, labels_10+10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = graphs\n",
    "X = X[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.get_dummies(labels[:,0])\n",
    "first[18] = 0\n",
    "first[19] = 0\n",
    "y = (first + pd.get_dummies(labels[:,1])).values\n",
    "first = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(input, target, size_average=True):\n",
    "    return torch.mean(-target * torch.log(input))\n",
    "\n",
    "\n",
    "class CNN(nn.Module): \n",
    "    \n",
    "    #constructor\n",
    "    #take in X as a parameter\n",
    "    def __init__(self, X, y, weight_decay = 0.0005):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.device = 'cpu'\n",
    "        \n",
    "        y_dim = y.shape[-1]\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(18 * 10 * 10, 64)\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(64, y_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay = weight_decay)\n",
    "        self.to(self.device)\n",
    "        \n",
    "    # 1. input X\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        \n",
    "        X = self.pool(X)\n",
    "    \n",
    "        X = X.view(-1, int(18 * 10 * 10))\n",
    "        \n",
    "        X = self.relu(self.fc1(X))\n",
    "        \n",
    "        #Computes the second fully connected layer (activation applied later)\n",
    "        #Size changes from (1, 64) to (1, 10)\n",
    "        X = self.fc2(X)\n",
    "        X = self.sigmoid(X)\n",
    "        X = 2*X/(X.sum(1)[:,None])\n",
    "        return X\n",
    "    \n",
    "    def loss(self, pred, true):\n",
    "        #PyTorch's own cross entropy loss function.\n",
    "        score = cross_entropy\n",
    "        l = None\n",
    "        for i in range(true.shape[1]):\n",
    "            if l is None:\n",
    "                l = score(pred[:,i], true[:,i])\n",
    "            else:\n",
    "                l += score(pred[:,i], true[:,i])\n",
    "        return l\n",
    "    \n",
    "\n",
    "    def fit(self, X, y, early_stopping = True, patience = 50):\n",
    "        \n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_arr = X.values\n",
    "            X_tens = Variable(torch.Tensor(X_arr).float())\n",
    "        else:\n",
    "            X_tens = Variable(torch.Tensor(X).float())\n",
    "        if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "            y_arr = y.values\n",
    "            if len(y_arr.shape) == 1:\n",
    "                y_arr = y_arr[:,None]\n",
    "            y_tens = Variable(torch.Tensor(y_arr).float())\n",
    "        else:\n",
    "            if len(y.shape) == 1:\n",
    "                y = y[:,None]\n",
    "            y_tens = Variable(torch.Tensor(y).float())\n",
    "        \n",
    "        X_tens = X_tens.to(self.device)\n",
    "        y_tens = y_tens.to(self.device)\n",
    "        \n",
    "        if early_stopping == True:\n",
    "            \n",
    "            inds = np.arange(len(X_tens))\n",
    "            num_train = int(len(X_tens) * .9)\n",
    "            train_inds = np.random.choice(inds, num_train, replace=False)\n",
    "            val_inds = np.setdiff1d(inds, train_inds)\n",
    "            X_train = X_tens[train_inds]\n",
    "            y_train = y_tens[train_inds]\n",
    "            X_val = X_tens[val_inds]\n",
    "            y_val = y_tens[val_inds]\n",
    "            \n",
    "        for epoch in range(1000):\n",
    "            self.optimizer.zero_grad()\n",
    "            if early_stopping==True:\n",
    "                out_train = self.forward(X_train)\n",
    "                loss = self.loss(out_train, y_train)\n",
    "            if early_stopping==False:\n",
    "                out_train = self.forward(X_tens)\n",
    "                loss = self.loss(out_train, y_tens)\n",
    "                print(loss)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                continue\n",
    "                \n",
    "            out_val = self.forward(X_val)\n",
    "            loss_val = self.loss(out_val, y_val)\n",
    "            print(loss_val)\n",
    "\n",
    "\n",
    "            if epoch == 0:\n",
    "                min_loss = loss_val\n",
    "                best_weights = self.state_dict()\n",
    "                counter = 0\n",
    "            else:\n",
    "                if loss_val < min_loss:\n",
    "                    min_loss = loss_val\n",
    "                    best_weights = self.state_dict()\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    if counter == patience:\n",
    "                        self.load_state_dict(best_weights)\n",
    "                        return\n",
    "                \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_arr = X.values\n",
    "            X_tens = Variable(torch.Tensor(X_arr).float())\n",
    "        else:\n",
    "            X_tens = Variable(torch.Tensor(X).float())\n",
    "            \n",
    "        X_tens = X_tens.to(self.device)\n",
    "        \n",
    "        predict_out = self.forward(X_tens)\n",
    "        temp =  predict_out.cpu().detach().numpy()\n",
    "        temp[temp > 1-1e-6] = 1-1e-6\n",
    "        temp[temp < 1e-6]=1e-6\n",
    "        return temp\n",
    "    \n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X).argsort(1)[:,-2:]\n",
    "        proba.sort(1)\n",
    "        return proba\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_true = y.argsort(1)[:,-2:]\n",
    "        y_true.sort(1)\n",
    "        return (y_pred == y_true).all(1).mean().item()\n",
    "    \n",
    "    def top_k_acc(self, X,y, k = 5):\n",
    "        \"\"\"Get top k accuracy for prediction. I.e., were the 2 correct nodes \n",
    "        in the top k returned. Note, k=2 is the score function.\"\"\"\n",
    "        y_pred = self.predict_proba(X)\n",
    "        y_true = y.argsort(1)[:,-2:]  \n",
    "        y_true.sort(1)\n",
    "        eqs_list = []\n",
    "        top_k = y_pred.argsort(1)[:,-k:]\n",
    "        for i in range(y_true.shape[0]):\n",
    "            row = y_true[i]\n",
    "            eqs_arr = []\n",
    "            for ele in row:\n",
    "                eqs_arr.append(np.any(ele == top_k[i]))\n",
    "            eqs_arr = np.array(eqs_arr)\n",
    "            eq = eqs_arr.all()\n",
    "            eqs_list.append(eq)\n",
    "        eqs = np.array(eqs_list)\n",
    "\n",
    "        return eqs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.7702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.5170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.1116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7015, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.2686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7553, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(X, y)\n",
    "\n",
    "cnn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6992"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8224"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.top_k_acc(X_test, y_test, k = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Tutorial]",
   "language": "python",
   "name": "conda-env-Tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
