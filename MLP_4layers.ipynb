{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP_4layers.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","id":"jKvjcrKTA_-F","colab":{}},"cell_type":"code","source":["import numpy as np\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torch.autograd import Variable\n","from torch.utils import data"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"3yc5liH3A_-I","colab":{}},"cell_type":"code","source":["graphs = np.load(\"graph_10+20k.npy\")\n","# options: graph_10+20k, graph_10+10k\n","labels = np.load(\"labels_10+20k.npy\")\n","# options: labels_10+20k, labels_10+10k"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"_4jK9z90A_-K","outputId":"c0d5ed8c-b27a-4b85-fe9f-3eaad7ca7b00","colab":{"base_uri":"https://localhost:8080/","height":1411}},"cell_type":"code","source":["num_of_graphs = graphs.shape[0]\n","num_of_nodes = graphs.shape[1]\n","\n","\n","def compress_graphs(graphs):\n","    \"\"\"Convert 3d matrix of graphs, dims = (graphs,verts,verts), \n","    to 2d matrix dims = (n_graphs, (verts choose 2) - verts). \n","    We can omit half of the data as the matrix of each graph is \n","    symmetric as we are working with undirected graphs. We can\n","    also not take any entries on the main diagonal as they will \n","    always be zero as we do not allow self loops.\n","    \n","    \n","    Args: \n","        graphs : (n_graphs,verts,verts) hypermatrix of graphs.\n","        \n","    Returns:\n","        graphs_comp : (n_graphs, (vert choose 2) - verts) matrix\n","            of compressed adjancey matrices.\n","        \n","        \n","    \"\"\"\n","    \n","    verts = graphs.shape[1]\n","    graphs_comp =  graphs.T[np.triu_indices(verts, 1)].T\n","    \n","    return graphs_comp  \n","\n","# compress 2d adjacency matrix to 1d array, prepare input\n","compressed_graph = np.zeros((graphs.shape[0], int(num_of_nodes*(num_of_nodes-1)/2)))\n","                            \n","for i in range(0,graphs.shape[0]):\n","    compressed_graph[i] = compress_graphs(graphs[i])\n","\n","graphs_train, graphs_test, train_labels, val_labels =\\\n","    train_test_split(compressed_graph, labels, test_size=0.20, random_state=42)\n","\n","batch_size = 64\n","params = {'batch_size': batch_size,\n","          'shuffle': True,\n","          'num_workers': 6}\n","max_epochs = 100\n","\n","class Dataset(data.Dataset):\n","  'Characterizes a dataset for PyTorch'\n","  def __init__(self, list_IDs, labels):\n","        'Initialization'\n","        self.labels = labels\n","        self.list_IDs = list_IDs\n","\n","  def __len__(self):\n","        'Denotes the total number of samples'\n","        return num_of_graphs\n","\n","  def __getitem__(self, index):\n","        'Generates one sample of data'\n","        # Select sample\n","        ID = index\n","\n","        # Load data and get label\n","        X = Variable(torch.from_numpy(compressed_graph[ID]))\n","        y = self.labels[ID]\n","\n","        return X, y\n","\n","# Generators\n","training_set = Dataset(graphs_train, labels)\n","training_generator = data.DataLoader(training_set, **params)\n","\n","validation_set = Dataset(graphs_test, labels)\n","validation_generator = data.DataLoader(validation_set, **params)\n","\n","class CompressMatrixNetwork(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        u = int(num_of_nodes*(num_of_nodes-1)/2)\n","        self.fc1 = nn.Linear(u, 380)\n","        self.fc2 = nn.Linear(380, 760)\n","        self.fc3 = nn.Linear(760, 85)\n","        self.fc4 = nn.Linear(85, 40)\n","        self.fc5 = nn.Linear(85, 40)\n","        self.fc6 = nn.Linear(40, num_of_nodes)\n","        self.fc7 = nn.Linear(40, num_of_nodes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x1 = F.relu(self.fc4(x))\n","        x1 = self.fc6(x1)\n","        x2 = F.relu(self.fc5(x))\n","        x2 = self.fc7(x2)\n","        return F.softmax(x1, dim=1), F.softmax(x2, dim=1)\n","\n","model = CompressMatrixNetwork()\n","\n","for module in model.children():\n","    module.reset_parameters()\n","\n","if torch.cuda.is_available():\n","    model.cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","optimizer.zero_grad()\n","\n","\n","info = []\n","# Loop over epochs\n","for epoch in range(max_epochs):\n","    epoch_train_acc, correct_count = 0, 0\n","    epoch_val_acc = 0\n","    epoch_train_loss = 0\n","    epoch_val_loss=0\n","    count = 0\n","    \n","    # Training\n","    for local_batch, local_labels in training_generator:\n","        # Transfer to GPU\n","        if torch.cuda.is_available():\n","            local_batch, local_labels = local_batch.cuda(), local_labels.cuda()\n","        \n","        model.train()\n","        \n","        label_batch = local_labels.long()\n","        input_batch = local_batch.float()\n","\n","        output_batch = model(input_batch)\n","\n","        train_loss = F.cross_entropy(output_batch[0], label_batch[:,0]) \\\n","            + F.cross_entropy(output_batch[1], label_batch[:,1])\n","        epoch_train_loss += train_loss\n","\n","        \n","        pred1 = output_batch[0].data.max(1)[1]\n","        pred2 = output_batch[1].data.max(1)[1]\n","        \n","        matches = (label_batch[:,0] == pred1) & (label_batch[:,1] == pred2)\n","        epoch_train_acc += matches.float().mean()\n","        correct_count += matches.sum()\n","        \n","        optimizer.zero_grad()\n","        \n","        train_loss.backward()\n","        optimizer.step()\n","        count += 1\n","    epoch_train_loss = epoch_train_loss / count\n","    epoch_train_acc = epoch_train_acc / count\n","    # Validation\n","    count = 0\n","    with torch.no_grad():\n","        for local_batch, local_labels in validation_generator:\n","            # Transfer to GPU\n","            local_batch, local_labels = local_batch.cuda(), local_labels.cuda()\n","\n","            model.eval()\n","            \n","            label_batch = local_labels.long()\n","            input_batch = local_batch.float()\n","            \n","            output_batch = model(input_batch)\n","            \n","            \n","            val_loss = F.cross_entropy(output_batch[0], label_batch[:,0]) \\\n","                + F.cross_entropy(output_batch[1], label_batch[:,1])\n","            epoch_val_loss += val_loss\n","\n","            pred1 = output_batch[0].data.max(1)[1]\n","            pred2 = output_batch[1].data.max(1)[1]\n","            \n","            matches = (label_batch[:,0] == pred1) & (label_batch[:,1] == pred2)\n","            epoch_val_acc += matches.float().mean()\n","            count += 1\n","        epoch_val_loss = epoch_val_loss / count\n","        epoch_val_acc = epoch_val_acc / count\n","    info.append([epoch, epoch_train_loss, epoch_val_loss, epoch_train_acc, epoch_val_acc])\n","    print('epoch {:5d}: Obtained a training acc of {:.3f}.'.format(epoch, epoch_train_acc))\n","    print('epoch {:5d}: Obtained a validation acc of {:.3f}.'.format(epoch, epoch_val_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch     0: Obtained a training acc of 0.002.\n","epoch     0: Obtained a validation acc of 0.002.\n","epoch     1: Obtained a training acc of 0.000.\n","epoch     1: Obtained a validation acc of 0.000.\n","epoch     2: Obtained a training acc of 0.000.\n","epoch     2: Obtained a validation acc of 0.000.\n","epoch     3: Obtained a training acc of 0.000.\n","epoch     3: Obtained a validation acc of 0.000.\n","epoch     4: Obtained a training acc of 0.000.\n","epoch     4: Obtained a validation acc of 0.005.\n","epoch     5: Obtained a training acc of 0.143.\n","epoch     5: Obtained a validation acc of 0.323.\n","epoch     6: Obtained a training acc of 0.361.\n","epoch     6: Obtained a validation acc of 0.366.\n","epoch     7: Obtained a training acc of 0.366.\n","epoch     7: Obtained a validation acc of 0.366.\n","epoch     8: Obtained a training acc of 0.366.\n","epoch     8: Obtained a validation acc of 0.366.\n","epoch     9: Obtained a training acc of 0.366.\n","epoch     9: Obtained a validation acc of 0.366.\n","epoch    10: Obtained a training acc of 0.366.\n","epoch    10: Obtained a validation acc of 0.366.\n","epoch    11: Obtained a training acc of 0.366.\n","epoch    11: Obtained a validation acc of 0.366.\n","epoch    12: Obtained a training acc of 0.366.\n","epoch    12: Obtained a validation acc of 0.366.\n","epoch    13: Obtained a training acc of 0.366.\n","epoch    13: Obtained a validation acc of 0.366.\n","epoch    14: Obtained a training acc of 0.366.\n","epoch    14: Obtained a validation acc of 0.366.\n","epoch    15: Obtained a training acc of 0.366.\n","epoch    15: Obtained a validation acc of 0.366.\n","epoch    16: Obtained a training acc of 0.366.\n","epoch    16: Obtained a validation acc of 0.366.\n","epoch    17: Obtained a training acc of 0.366.\n","epoch    17: Obtained a validation acc of 0.366.\n","epoch    18: Obtained a training acc of 0.366.\n","epoch    18: Obtained a validation acc of 0.366.\n","epoch    19: Obtained a training acc of 0.366.\n","epoch    19: Obtained a validation acc of 0.366.\n","epoch    20: Obtained a training acc of 0.366.\n","epoch    20: Obtained a validation acc of 0.366.\n","epoch    21: Obtained a training acc of 0.366.\n","epoch    21: Obtained a validation acc of 0.366.\n","epoch    22: Obtained a training acc of 0.366.\n","epoch    22: Obtained a validation acc of 0.366.\n","epoch    23: Obtained a training acc of 0.366.\n","epoch    23: Obtained a validation acc of 0.366.\n","epoch    24: Obtained a training acc of 0.366.\n","epoch    24: Obtained a validation acc of 0.366.\n","epoch    25: Obtained a training acc of 0.366.\n","epoch    25: Obtained a validation acc of 0.366.\n","epoch    26: Obtained a training acc of 0.366.\n","epoch    26: Obtained a validation acc of 0.366.\n","epoch    27: Obtained a training acc of 0.366.\n","epoch    27: Obtained a validation acc of 0.366.\n","epoch    28: Obtained a training acc of 0.366.\n","epoch    28: Obtained a validation acc of 0.366.\n","epoch    29: Obtained a training acc of 0.366.\n","epoch    29: Obtained a validation acc of 0.366.\n","epoch    30: Obtained a training acc of 0.366.\n","epoch    30: Obtained a validation acc of 0.366.\n","epoch    31: Obtained a training acc of 0.366.\n","epoch    31: Obtained a validation acc of 0.366.\n","epoch    32: Obtained a training acc of 0.366.\n","epoch    32: Obtained a validation acc of 0.366.\n","epoch    33: Obtained a training acc of 0.366.\n","epoch    33: Obtained a validation acc of 0.366.\n","epoch    34: Obtained a training acc of 0.366.\n","epoch    34: Obtained a validation acc of 0.366.\n","epoch    35: Obtained a training acc of 0.366.\n","epoch    35: Obtained a validation acc of 0.366.\n","epoch    36: Obtained a training acc of 0.366.\n","epoch    36: Obtained a validation acc of 0.366.\n","epoch    37: Obtained a training acc of 0.366.\n","epoch    37: Obtained a validation acc of 0.366.\n","epoch    38: Obtained a training acc of 0.366.\n","epoch    38: Obtained a validation acc of 0.366.\n","epoch    39: Obtained a training acc of 0.366.\n","epoch    39: Obtained a validation acc of 0.366.\n","epoch    40: Obtained a training acc of 0.366.\n","epoch    40: Obtained a validation acc of 0.366.\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"2bDmOMYUA_-M","colab":{}},"cell_type":"code","source":["x, y11, y12, y21, y22 = zip(*info)\n","fig, ax = plt.subplots(2, 1, sharex=True)\n","ax[0].plot(x, y11, x, y12)\n","ax[0].legend(['Train loss', 'Val loss'])\n","ax[1].plot(x, y21, x, y22)\n","ax[1].legend(['Train acc', 'Val acc'])\n","ax[1].set_ylim([0.0, 1.0])"],"execution_count":0,"outputs":[]}]}